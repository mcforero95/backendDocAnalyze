
# ğŸ“„ Backend y Frontend de AnÃ¡lisis de Documentos con LLM

Proyecto para anÃ¡lisis, resumen y consulta de documentos utilizando FastAPI, recuperaciÃ³n de contexto (RAG), Gemini IA y PostgreSQL.

---

## ğŸš€ TecnologÃ­as utilizadas

- **Backend:** Python 3.10, FastAPI, PostgreSQL, Alembic
- **LLM:** Gemini IA de Google vÃ­a API (antes: llama.cpp con modelo `.gguf`)
- **Embeddings locales:** Sentence Transformers (`all-MiniLM-L6-v2`)
- **OrquestaciÃ³n:** Docker y Docker Compose

---

## ğŸ› ï¸ InstalaciÃ³n y ejecuciÃ³n local

### âœ… Requisitos previos

- Docker y Docker Compose
- Clave de API de Google para Gemini IA
- Variables de entorno configuradas

### âœ… Variables de entorno

```env
# Base de datos PostgreSQL (nombre del servicio dentro del docker-compose)
DATABASE_URL=postgresql://postgres:analyzedb@postgres:5432/analyze_db
POSTGRES_DB=analyze_db
POSTGRES_USER=postgres
POSTGRES_PASSWORD=analyzedb
POSTGRES_HOST=postgres
POSTGRES_PORT=5432

# Seguridad JWT
ALGORITHM=HS256
ACCESS_TOKEN_EXPIRE_MINUTES=30

# Ruta del modelo de lenguaje`
GEMINI_API_KEY=Aqui tu apikey
GEMINI_MODEL_NAME=gemini-2.0-flash

# Redis (para Celery)
REDIS_URL=redis://redis:6379/0
```

---

## âœ… ConstrucciÃ³n y ejecuciÃ³n

```bash
docker-compose build --no-cache
docker-compose up -d
```

Accede a:

- **Frontend:** http://localhost:80/
- **API Docs:** http://localhost:8000/docs

---

## ğŸ§  Funcionalidades clave

- âœ… Subida de documentos (`.pdf`, `.docx`, `.txt`)
- âœ… ExtracciÃ³n y segmentaciÃ³n del texto en *chunks*
- âœ… GeneraciÃ³n de **embeddings** por chunk
- âœ… Resumen del documento usando **Gemini**
- âœ… Chat con el documento vÃ­a preguntas/respuestas
- âœ… **RecuperaciÃ³n de Contexto (RAG)** con chunks relevantes
- âœ… Historial de conversaciones y mensajes por usuario

---

## ğŸ“Œ CÃ³mo usar RAG

### Endpoint:
`POST /ask/{document_id}?rag=true`

### ParÃ¡metros:

| Nombre    | Tipo   | DescripciÃ³n                                 |
|-----------|--------|---------------------------------------------|
| rag       | bool   | (Opcional) Si se usa RAG. Default: false    |

### Body:

| question  | Pregunta del usuario                        |

---

## ğŸ§± Modelo de datos principal

### ğŸ“„ `documents`
- `id`, `title`, `content`, `owner_id`

### ğŸ§© `document_chunks`
- `id`, `document_id`, `chunk_text`, `embedding`, `chunk_index`

### ğŸ’¬ `conversations`
- `id`, `user_id`, `document_id`, `created_at`

### ğŸ’­ `messages`
- `id`, `conversation_id`, `question`, `answer`, `created_at`

---

## ğŸ§ª Alembic (migraciÃ³n de base de datos)

```bash
alembic revision --autogenerate -m "initial"
alembic upgrade head
```

---

### âœ… ConstrucciÃ³n y ejecuciÃ³n

Desde la carpeta del backend (`backendDocAnalyze/`):

#### ğŸ”¹ Construir los contenedores:
```bash
docker-compose build --no-cache
```

#### ğŸ”¹ Levantar los contenedores:
```bash
docker-compose up -d
```

#### ğŸ”¹ Ver logs en tiempo real del backend:
```bash
docker logs -f backend_doc_analyze
```

#### ğŸ”¹ Detener todos los contenedores:
```bash
docker-compose down
```

#### ğŸ”¹ Limpiar contenedores e imÃ¡genes:
```bash
docker system prune -a
```

### âœ… Alembic (migraciÃ³n de base de datos)

#### ğŸ”¹ Primer uso:

1. Accede al backend:
    ```bash
    docker exec -it backend_doc_analyze bash
    ```

2. Crea la carpeta de migraciones (si no existe):
    ```bash
    mkdir -p /app/alembic/versions
    ```

3. Genera la migraciÃ³n inicial:
    ```bash
    alembic revision --autogenerate -m "Initial migration"
    alembic upgrade head
    ```

## ğŸŒ Accesos

- **Frontend:** http://localhost:80/
- **Backend (FastAPI docs):** http://localhost:8000/docs

## âš ï¸ Uso de recursos

Por defecto, los contenedores utilizan **todos los recursos disponibles** (CPU y RAM) de la mÃ¡quina donde se ejecuten.  
Si se requiere limitar los recursos, se debe modificar manualmente el archivo `docker-compose.yml` aÃ±adiendo el bloque `deploy.resources.limits`.

## âœ… ExportaciÃ³n de contenedores para compartir

### ğŸ”¹ Exportar los contenedores:
```bash
docker save -o backenddocanalyze-frontend.tar backenddocanalyze-frontend:latest
docker save -o backenddocanalyze-app.tar backenddocanalyze-app:latest
docker save -o postgres.tar postgres:16
docker save -o redis.tar redis:7
```

### ğŸ”¹ ImportaciÃ³n en otra mÃ¡quina de contenedores:

1. Descargga los contenedores y carga las imÃ¡genes:
    ```bash
    docker load -i backenddocanalyze-app.tar
    docker load -i postgres.tar
    docker load -i redis.tar
    docker load -i backenddocanalyze-frontend.tar
    ```

3. Levantar los servicios:
    ```bash
    docker-compose up -d
    ```
