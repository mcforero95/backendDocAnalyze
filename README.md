
# ğŸ“„ Backend y Frontend de AnÃ¡lisis de Documentos con LLM

Proyecto para anÃ¡lisis, resumen y consulta de documentos utilizando FastAPI, recuperaciÃ³n de contexto (RAG), Gemini IA y PostgreSQL.

---

## ğŸš€ TecnologÃ­as utilizadas

- **Backend:** Python 3.10, FastAPI, PostgreSQL, Alembic
- **LLM:** Gemini IA de Google vÃ­a API (antes: llama.cpp con modelo `.gguf`)
- **Embeddings locales:** Sentence Transformers (`all-MiniLM-L6-v2`)
- **OrquestaciÃ³n:** Docker y Docker Compose

---

## ğŸ› ï¸ InstalaciÃ³n y ejecuciÃ³n local

### âœ… Requisitos previos

- Docker y Docker Compose
- Clave de API de Google para Gemini IA
- Variables de entorno configuradas

### âœ… Variables de entorno

```env
# Base de datos PostgreSQL (nombre del servicio dentro del docker-compose)
DATABASE_URL=postgresql://postgres:analyzedb@<IP VM>:5432/analyze_db
POSTGRES_DB=analyze_db
POSTGRES_USER=postgres
POSTGRES_PASSWORD=analyzedb
POSTGRES_HOST=<IP VM>
POSTGRES_PORT=5432

# Ruta de los archivos compartidos
SHARED_FILES_PATH=/mnt/nfs_shared

# Seguridad JWT
ALGORITHM=HS256
ACCESS_TOKEN_EXPIRE_MINUTES=30

# Ruta del modelo de lenguaje`
GEMINI_API_KEY=Aqui tu apikey
GEMINI_MODEL_NAME=gemini-2.0-flash

# Redis (para Celery)
REDIS_URL=redis://redis:6379/0
```

---

## ğŸ§  Funcionalidades clave

- âœ… Subida de documentos (`.pdf`, `.docx`, `.txt`)
- âœ… ExtracciÃ³n y segmentaciÃ³n del texto en *chunks*
- âœ… GeneraciÃ³n de **embeddings** por chunk
- âœ… Resumen del documento usando **Gemini**
- âœ… Chat con el documento vÃ­a preguntas/respuestas
- âœ… **RecuperaciÃ³n de Contexto (RAG)** con chunks relevantes
- âœ… Historial de conversaciones y mensajes por usuario

---

## ğŸ“Œ CÃ³mo usar RAG

### Endpoint:
`POST /ask/{document_id}?rag=true`

### ParÃ¡metros:

| Nombre    | Tipo   | DescripciÃ³n                                 |
|-----------|--------|---------------------------------------------|
| rag       | bool   | (Opcional) Si se usa RAG. Default: false    |

### Body:

| question  | Pregunta del usuario                        |

---

## ğŸ§± Modelo de datos principal

### ğŸ“„ `documents`
- `id`, `title`, `content`, `owner_id`

### ğŸ§© `document_chunks`
- `id`, `document_id`, `chunk_text`, `embedding`, `chunk_index`

### ğŸ’¬ `conversations`
- `id`, `user_id`, `document_id`, `created_at`

### ğŸ’­ `messages`
- `id`, `conversation_id`, `question`, `answer`, `created_at`

---

### âœ… ConstrucciÃ³n y ejecuciÃ³n

Desde la carpeta del backend (`backendDocAnalyze/`):

#### ğŸ”¹ Construir los contenedores:

Para iniciar en una VM GCP: 

```bash
docker-compose -f docker-compose.worker.yml build --no-cache
```
Para iniciar local:

```bash
docker-compose -f docker-compose.yml build --no-cache
```

#### ğŸ”¹ Levantar los contenedores:

Para levantar en una VM GCP:

```bash
docker-compose -f docker-compose.worker.yml up -d
```

Para levantar en local:

```bash
docker-compose -f docker-compose.yml up -d
```

#### ğŸ”¹ Ver logs en tiempo real del backend:
```bash
docker logs -f backend_doc_analyze
```

#### ğŸ”¹ Detener todos los contenedores:
```bash
docker-compose down
```

#### ğŸ”¹ Limpiar contenedores e imÃ¡genes:
```bash
docker system prune -a
```


### âœ… Alembic (migraciÃ³n de base de datos)

#### Solo para primer uso o instalaciÃ³n:

1. Accede al backend:
    ```bash
    docker exec -it backend_doc_analyze bash
    ```

2. Crea la carpeta de migraciones (si no existe):
    ```bash
    mkdir -p /app/alembic/versions
    ```

3. Genera la migraciÃ³n inicial:
    ```bash
    alembic revision --autogenerate -m "Initial migration"
    alembic upgrade head
    ```

## ğŸŒ Accesos

- **Frontend:** http://localhost:80/
- **Backend (FastAPI docs):** http://localhost:8000/docs

## âš ï¸ Uso de recursos

Por defecto, los contenedores utilizan **todos los recursos disponibles** (CPU y RAM) de la mÃ¡quina donde se ejecuten.  
Si se requiere limitar los recursos, se debe modificar manualmente el archivo `docker-compose.yml` aÃ±adiendo el bloque `deploy.resources.limits`.